apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    prometheus: general-platform-alerts
    role: general-paltform-alert-rules
    app: prometheus-operator
    release: prometheus-operator
  name: general-platform-alerts
spec:
  groups:
  - name: certificates.rules
    rules:
    - alert: SSLCertExpiringSoon
      expr: sum by (target, instance) (probe_ssl_earliest_cert_expiry{job="blackbox-exporter-prometheus-blackbox-exporter"} - time()) < 86400 * 20
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'SSL certificate for {{ $labels.instance }} expires in less than 20 days.'
  # - name: job.rules
  #   rules:
  #   - alert: JobsNotCleanedUp
  #     expr: count by (namespace) (kube_job_status_completion_time < (time() - 86400)) > 20
  #     for: 2m
  #     labels:
  #       severity: major
  #     annotations:
  #       message: 'Namespace {{ $labels.namespace }} has {{ $value }} completed jobs.'
  - name: meta-alerts.rules
    rules:
    - record: alerts_firing
      expr: sum without (alertname, alertstate) (label_replace(ALERTS{alertstate="firing",alertname!="ManyAlertsFiring"}, "alertfiring", "$1", "alertname", "(.*)"))
    - alert: ManyManyAlertsFiring
      expr: sum by(alertfiring, namespace) (alerts_firing) > 50
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: '{{ $value }} instances of alert {{ $labels.alertfiring }} are firing in namespace {{ $labels.namespace }}!'
    - alert: ManyAlertsFiring
      expr: sum by(alertfiring, namespace) (alerts_firing) > 20
      for: 2m
      labels:
        severity: major
      annotations:
        message: '{{ $value }} instances of alert {{ $labels.alertfiring }} are firing in namespace {{ $labels.namespace }}.'
  - name: nodepool-status.rules
    rules:
    - record: nodepool_allocatable_pods
      expr: sum(kube_node_status_allocatable_pods * on (node) group_left(label_agentpool) kube_node_labels) by (label_agentpool)
    - record: nodepool_allocated_pods
      expr: sum(kube_pod_info * on (node) group_left(label_agentpool) kube_node_labels) by (label_agentpool)
    - alert: NodepoolPodsFull
      expr: nodepool_allocated_pods/nodepool_allocatable_pods * 100 > 95
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: '{{ if eq $labels.label_agentpool ""}}Unpooled node{{ else }}Nodepool {{ $labels.label_agentpool }}{{end}} pod capacity is {{ printf "%.2f" $value }}% full!'
    - alert: NodepoolLowPodCapacity
      expr: nodepool_allocated_pods/nodepool_allocatable_pods * 100 > 80
      for: 5m
      labels:
        severity: urgent
      annotations:
        message: '{{ if eq $labels.label_agentpool ""}}Unpooled node{{ else }}Nodepool {{ $labels.label_agentpool }}{{end}} pod capacity is {{ printf "%.2f" $value }}% full.'
  - name: node-status.rules
    rules:
    - record: node_cpu_available
      expr: sum by(nodename) (avg by(instance, job) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * on(instance, job) group_left(nodename) node_uname_info * 100)
    - alert: NodeDiskPressure
      expr: sum by (node) (kube_node_status_condition{condition="DiskPressure",job="kube-state-metrics",status="true"}) == 1
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'UNHEALTHY NODE: {{ $labels.node }} has critically low disk capacity.'
    - alert: NodeMemoryPressure
      expr: sum by (node) (kube_node_status_condition{condition="MemoryPressure",job="kube-state-metrics",status="true"}) == 1
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'UNHEALTHY NODE: {{ $labels.node }} has critically low memory.'
    - alert: NodePIDPressure
      expr: sum by (node) (kube_node_status_condition{condition="PIDPressure",job="kube-state-metrics",status="true"}) == 1
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'UNHEALTHY NODE: Too many processes are running on {{ $labels.node }}.'
    - alert: NodeNetworkUnavailable
      expr: sum by (node) (kube_node_status_condition{condition="NetworkUnavailable",job="kube-state-metrics",status="true"}) == 1
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'UNHEALTHY NODE: The network for {{ $labels.node }} is not correctly configured.'
    - alert: NodeNotReady
      expr: sum by (node) (kube_node_status_condition{condition="Ready",job="kube-state-metrics",status="true"}) == 0
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: '{{ $labels.node }} is not in a Ready state but did not trip a Network or Pressure condition.'
    - alert: NodeUnschedulable
      expr: sum by (node) (kube_node_spec_unschedulable{job="kube-state-metrics"}) == 1
      for: 1h
      labels:
        severity: urgent
      annotations:
        message: '{{ $labels.node }} is unschedulable for over 1 hour. If it is healthy, is it cordoned?'
    - alert: NodePodsFull
      expr: sum(kube_pod_info) by (node) / sum(kube_node_status_allocatable_pods) by (node) * 100 > 99
      for: 5m
      labels:
        severity: minor
      annotations:
        message: '{{ $labels.node }} pod capacity is {{ printf "%.2f" $value }}% full!'
    - alert: NodeLowMemory
      expr: sum by (nodename) (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * on(instance,job) group_left(nodename) node_uname_info * 100) < 15
      for: 10m
      labels:
        severity: minor
      annotations:
        message: '{{ $labels.nodename }} has {{ printf "%.2f" $value }}% available memory.'
    - alert: NodeLowDisk
      expr: sum by (nodename, device, mountpoint, fstype) (node_filesystem_avail_bytes / node_filesystem_size_bytes * on(instance,job) group_left(nodename) node_uname_info * 100) < 15
      for: 5m
      labels:
        severity: major
      annotations:
        message: '{{ $labels.device }} on {{ $labels.nodename }} has {{ printf "%.2f" $value }}% available disk space.'
    - alert: NodeLowCPU
      expr: avg_over_time(node_cpu_available[3m:]) < 15
      for: 5m
      labels:
        severity: minor
      annotations:
        message: '{{ $labels.nodename }} has {{ printf "%.2f" $value }}% available CPU.'
    - alert: NodeLowPodCapacity
      expr: sum(kube_pod_info) by (node) / sum(kube_node_status_allocatable_pods) by (node) * 100 > 90
      for: 5m
      labels:
        severity: minor
      annotations:
        message: '{{ $labels.node }} pod capacity is {{ printf "%.2f" $value }}% full.'
  - name: prometheus-extended.rules
    rules:
    - alert: PrometheusStorageLow
      expr: >-
        sum by (persistentvolumeclaim, namespace, node) 
        (kubelet_volume_stats_available_bytes{persistentvolumeclaim="prometheus-prometheus-operator-prometheus-db-prometheus-prometheus-operator-prometheus-0"}
        /kubelet_volume_stats_capacity_bytes{persistentvolumeclaim="prometheus-prometheus-operator-prometheus-db-prometheus-prometheus-operator-prometheus-0"}) * 100 < 10
      for: 2m
      labels:
        severity: urgent
      annotations:
        message: 'Prometheus storage has {{ $value }} capacity remaining.'
