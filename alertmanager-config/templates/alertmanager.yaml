#alertmanager configuration secret
#To-do: Pipeline this
global:
  resolve_timeout: 5m
receivers:
- name: cloud_slack
  slack_configs: 
  - api_url: {{ .Values.cloud_slack_incoming_webhook | squote }}
    channel: '#prometheus-alerts'
    send_resolved: true
    title: {{`'{{ template "slack.slackcustom.title" . }}'`}}
    text: {{`'{{ template "slack.slackcustom.text" . }}'`}}
- name: black_hole #Empty default receiver
# To do: come up with a low/info-severity route, or else configure Prometheus to not send low/info-severity to AlertManager.
# Ref: https://github.com/prometheus/alertmanager/issues/428#issuecomment-468952018
route:
  group_by: ['alertname', 'namespace']
  group_interval: 24h
  group_wait: 2m
  receiver: black_hole
  repeat_interval: 1w
  routes:
  - match:
      severity: supercritical
    receiver: cloud_slack
# Don't alert generic NodeNotReady when there is a known cause
inhibit_rules:
  - target_match:
      alertname: 'NodeNotReady'
    source_match_re:
      alertname: '(NodeDiskPressure|NodeMemoryPressure|NodePIDPressure|NodeMemoryPressure|NodeNetworkUnavailable)'
templates:
- '*.tmpl'
